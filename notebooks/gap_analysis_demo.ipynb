{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordination Gap Detection Demo\n",
    "\n",
    "This notebook demonstrates the coordination gap detection system's capabilities using realistic mock data scenarios.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Loading Data**: How to work with mock Slack scenarios\n",
    "2. **Gap Detection**: Running the detection pipeline\n",
    "3. **Entity Extraction**: Identifying teams, people, and projects\n",
    "4. **Impact Analysis**: Understanding gap severity and cost\n",
    "5. **Visualization**: Exploring coordination patterns\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Ensure the API is running:\n",
    "```bash\n",
    "docker compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if not already available)\n",
    "# !pip install requests pandas matplotlib seaborn networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any\n",
    "import json\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. API Client Setup\n",
    "\n",
    "Let's create a simple client to interact with the Gap Detection API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GapDetectionClient:\n",
    "    \"\"\"Simple client for interacting with the Gap Detection API.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = \"http://localhost:8000\"):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def detect_gaps(\n",
    "        self,\n",
    "        timeframe_days: int = 30,\n",
    "        gap_types: List[str] = None,\n",
    "        min_impact_score: float = 0.6,\n",
    "        include_evidence: bool = True,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Run gap detection.\"\"\"\n",
    "        payload = {\n",
    "            \"timeframe_days\": timeframe_days,\n",
    "            \"gap_types\": gap_types or [\"duplicate_work\"],\n",
    "            \"min_impact_score\": min_impact_score,\n",
    "            \"include_evidence\": include_evidence,\n",
    "        }\n",
    "        \n",
    "        response = self.session.post(\n",
    "            f\"{self.base_url}/api/v1/gaps/detect\",\n",
    "            json=payload,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    def list_gaps(\n",
    "        self,\n",
    "        gap_type: str = None,\n",
    "        min_impact_score: float = None,\n",
    "        limit: int = 10,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"List existing gaps.\"\"\"\n",
    "        params = {\"limit\": limit}\n",
    "        if gap_type:\n",
    "            params[\"gap_type\"] = gap_type\n",
    "        if min_impact_score:\n",
    "            params[\"min_impact_score\"] = min_impact_score\n",
    "        \n",
    "        response = self.session.get(\n",
    "            f\"{self.base_url}/api/v1/gaps\",\n",
    "            params=params,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    def get_gap(self, gap_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get specific gap details.\"\"\"\n",
    "        response = self.session.get(f\"{self.base_url}/api/v1/gaps/{gap_id}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "# Initialize client\n",
    "client = GapDetectionClient()\n",
    "print(\"✓ API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Mock Data Scenarios\n",
    "\n",
    "The system includes 6 realistic mock data scenarios:\n",
    "\n",
    "### Positive Cases (Should Detect Gaps)\n",
    "1. **OAuth Duplication**: Platform and Auth teams independently implementing OAuth2\n",
    "2. **API Redesign**: Mobile and Backend teams duplicating API work\n",
    "3. **Auth Migration**: Security and Platform duplicating JWT migration\n",
    "\n",
    "### Edge Cases (Should NOT Detect)\n",
    "4. **Similar Topics, Different Scope**: User auth vs service auth (different purposes)\n",
    "5. **Sequential Work**: Team B starts after Team A completes (no overlap)\n",
    "6. **Intentional Collaboration**: Teams explicitly coordinating together\n",
    "\n",
    "Let's load the OAuth duplication scenario as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In production, data would be loaded from Slack/GitHub/etc.\n",
    "# For this demo, we'll use the mock data scenarios\n",
    "\n",
    "print(\"Mock data scenarios available:\")\n",
    "print(\"\"\"\\n",
    "1. oauth_duplication - Platform and Auth teams independently implementing OAuth2\n",
    "2. api_redesign_duplication - Mobile and Backend duplicating API work  \n",
    "3. auth_migration_duplication - Security and Platform duplicating JWT migration\n",
    "4. similar_topics_different_scope - Different scopes (should NOT detect)\n",
    "5. sequential_work - No temporal overlap (should NOT detect)\n",
    "6. intentional_collaboration - Explicit coordination (should NOT detect)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Gap Detection\n",
    "\n",
    "Let's run the detection pipeline and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gap detection\n",
    "print(\"Running gap detection...\")\n",
    "detection_result = client.detect_gaps(\n",
    "    timeframe_days=30,\n",
    "    gap_types=[\"duplicate_work\"],\n",
    "    min_impact_score=0.6,\n",
    "    include_evidence=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Detection complete!\")\n",
    "print(f\"  - Total gaps detected: {detection_result['metadata']['total_gaps']}\")\n",
    "print(f\"  - Messages analyzed: {detection_result['metadata']['messages_analyzed']}\")\n",
    "print(f\"  - Detection time: {detection_result['metadata']['detection_time_ms']}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Detected Gaps\n",
    "\n",
    "Let's examine the gaps that were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gaps to DataFrame for easy analysis\n",
    "gaps = detection_result.get('gaps', [])\n",
    "\n",
    "if gaps:\n",
    "    # Create summary DataFrame\n",
    "    gap_summary = pd.DataFrame([\n",
    "        {\n",
    "            'Gap ID': gap['id'],\n",
    "            'Type': gap['type'],\n",
    "            'Topic': gap.get('topic', 'N/A'),\n",
    "            'Teams': ', '.join(gap.get('teams_involved', [])),\n",
    "            'Impact Score': gap['impact_score'],\n",
    "            'Confidence': gap['confidence'],\n",
    "            'Evidence Count': len(gap.get('evidence', [])),\n",
    "        }\n",
    "        for gap in gaps\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nDetected Gaps Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    display(gap_summary)\n",
    "else:\n",
    "    print(\"\\nNo gaps detected in the current dataset.\")\n",
    "    print(\"This is expected if:\")\n",
    "    print(\"  - Detection algorithm is not fully implemented yet\")\n",
    "    print(\"  - No duplicate work scenarios are loaded\")\n",
    "    print(\"  - Thresholds are too strict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deep Dive: Gap Evidence Analysis\n",
    "\n",
    "Let's examine the evidence for the first detected gap (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps:\n",
    "    # Analyze first gap in detail\n",
    "    gap = gaps[0]\n",
    "    \n",
    "    print(f\"Gap Analysis: {gap['id']}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nType: {gap['type']}\")\n",
    "    print(f\"Topic: {gap.get('topic', 'N/A')}\")\n",
    "    print(f\"Teams Involved: {', '.join(gap.get('teams_involved', []))}\")\n",
    "    print(f\"Impact Score: {gap['impact_score']:.2f}\")\n",
    "    print(f\"Confidence: {gap['confidence']:.2f}\")\n",
    "    \n",
    "    # Evidence timeline\n",
    "    evidence = gap.get('evidence', [])\n",
    "    if evidence:\n",
    "        print(f\"\\nEvidence ({len(evidence)} items):\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        evidence_df = pd.DataFrame([\n",
    "            {\n",
    "                'Source': e.get('source', 'N/A'),\n",
    "                'Author': e.get('author', 'N/A'),\n",
    "                'Channel': e.get('channel', 'N/A'),\n",
    "                'Timestamp': e.get('timestamp', 'N/A'),\n",
    "                'Preview': e.get('content', '')[:60] + '...' if len(e.get('content', '')) > 60 else e.get('content', ''),\n",
    "            }\n",
    "            for e in evidence[:10]  # Show first 10\n",
    "        ])\n",
    "        \n",
    "        display(evidence_df)\n",
    "    \n",
    "    # Recommendation\n",
    "    if 'recommendation' in gap:\n",
    "        print(f\"\\nRecommendation:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(gap['recommendation'])\n",
    "else:\n",
    "    print(\"No gaps available for detailed analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entity Extraction Analysis\n",
    "\n",
    "Let's analyze the entities (teams, people, projects) involved in detected gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps:\n",
    "    # Extract all entities from gaps\n",
    "    all_teams = set()\n",
    "    all_people = set()\n",
    "    all_projects = set()\n",
    "    \n",
    "    for gap in gaps:\n",
    "        all_teams.update(gap.get('teams_involved', []))\n",
    "        \n",
    "        # Extract from evidence\n",
    "        for evidence in gap.get('evidence', []):\n",
    "            if 'author' in evidence:\n",
    "                all_people.add(evidence['author'])\n",
    "            if 'team' in evidence.get('metadata', {}):\n",
    "                all_teams.add(evidence['metadata']['team'])\n",
    "    \n",
    "    print(\"Entity Extraction Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTeams involved: {len(all_teams)}\")\n",
    "    for team in sorted(all_teams):\n",
    "        print(f\"  - {team}\")\n",
    "    \n",
    "    print(f\"\\nPeople involved: {len(all_people)}\")\n",
    "    for person in sorted(all_people):\n",
    "        print(f\"  - {person}\")\n",
    "    \n",
    "    # Team co-occurrence matrix\n",
    "    teams_list = list(all_teams)\n",
    "    if len(teams_list) >= 2:\n",
    "        print(\"\\nTeam Co-occurrence in Gaps:\")\n",
    "        team_cooccurrence = pd.DataFrame(\n",
    "            0, \n",
    "            index=teams_list, \n",
    "            columns=teams_list\n",
    "        )\n",
    "        \n",
    "        for gap in gaps:\n",
    "            involved = gap.get('teams_involved', [])\n",
    "            for t1 in involved:\n",
    "                for t2 in involved:\n",
    "                    if t1 in team_cooccurrence.index and t2 in team_cooccurrence.columns:\n",
    "                        team_cooccurrence.loc[t1, t2] += 1\n",
    "        \n",
    "        display(team_cooccurrence)\n",
    "else:\n",
    "    print(\"No entities to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Impact Score Distribution\n",
    "\n",
    "Let's visualize the distribution of impact scores across detected gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps and len(gaps) > 0:\n",
    "    # Extract impact scores\n",
    "    impact_scores = [gap['impact_score'] for gap in gaps]\n",
    "    confidence_scores = [gap['confidence'] for gap in gaps]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Impact score distribution\n",
    "    axes[0].hist(impact_scores, bins=10, edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(0.8, color='red', linestyle='--', label='Critical (0.8+)')\n",
    "    axes[0].axvline(0.6, color='orange', linestyle='--', label='High (0.6+)')\n",
    "    axes[0].set_xlabel('Impact Score')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Gap Impact Score Distribution')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Confidence vs Impact scatter\n",
    "    axes[1].scatter(confidence_scores, impact_scores, alpha=0.6, s=100)\n",
    "    axes[1].axhline(0.8, color='red', linestyle='--', alpha=0.5, label='Critical Impact')\n",
    "    axes[1].axhline(0.6, color='orange', linestyle='--', alpha=0.5, label='High Impact')\n",
    "    axes[1].axvline(0.7, color='blue', linestyle='--', alpha=0.5, label='Min Confidence')\n",
    "    axes[1].set_xlabel('Confidence Score')\n",
    "    axes[1].set_ylabel('Impact Score')\n",
    "    axes[1].set_title('Confidence vs Impact')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nImpact Score Statistics:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Mean: {pd.Series(impact_scores).mean():.2f}\")\n",
    "    print(f\"Median: {pd.Series(impact_scores).median():.2f}\")\n",
    "    print(f\"Std Dev: {pd.Series(impact_scores).std():.2f}\")\n",
    "    print(f\"Min: {pd.Series(impact_scores).min():.2f}\")\n",
    "    print(f\"Max: {pd.Series(impact_scores).max():.2f}\")\n",
    "else:\n",
    "    print(\"No gaps available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Gap Type Breakdown\n",
    "\n",
    "Analyze the distribution of different gap types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps and len(gaps) > 0:\n",
    "    # Count by type\n",
    "    gap_types = pd.Series([gap['type'] for gap in gaps]).value_counts()\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart\n",
    "    gap_types.plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='black')\n",
    "    axes[0].set_xlabel('Gap Type')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].set_title('Gaps by Type')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Pie chart\n",
    "    gap_types.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_ylabel('')\n",
    "    axes[1].set_title('Gap Type Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nGap Type Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    for gap_type, count in gap_types.items():\n",
    "        print(f\"{gap_type}: {count} ({count/len(gaps)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No gaps available for type analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Temporal Analysis\n",
    "\n",
    "Analyze when gaps were detected over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps and len(gaps) > 0:\n",
    "    # Extract detection timestamps\n",
    "    gap_dates = []\n",
    "    for gap in gaps:\n",
    "        if 'detected_at' in gap:\n",
    "            gap_dates.append(pd.to_datetime(gap['detected_at']))\n",
    "    \n",
    "    if gap_dates:\n",
    "        # Create timeline\n",
    "        gap_timeline = pd.Series(1, index=gap_dates)\n",
    "        daily_gaps = gap_timeline.resample('D').sum()\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        daily_gaps.plot(kind='line', marker='o', linewidth=2, markersize=8)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Gaps Detected')\n",
    "        plt.title('Gap Detection Timeline')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nTemporal Statistics:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"First gap detected: {min(gap_dates).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Latest gap detected: {max(gap_dates).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Total days with gaps: {(daily_gaps > 0).sum()}\")\n",
    "        print(f\"Average gaps per day: {daily_gaps.mean():.2f}\")\n",
    "    else:\n",
    "        print(\"No temporal data available for gaps.\")\n",
    "else:\n",
    "    print(\"No gaps available for temporal analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cost Estimation\n",
    "\n",
    "Estimate the organizational cost of detected coordination gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps and len(gaps) > 0:\n",
    "    # Cost estimation parameters\n",
    "    AVG_HOURLY_RATE = 100  # $100/hour loaded engineer cost\n",
    "    \n",
    "    total_estimated_hours = 0\n",
    "    gap_costs = []\n",
    "    \n",
    "    for gap in gaps:\n",
    "        # Estimate hours based on impact score and evidence\n",
    "        impact = gap['impact_score']\n",
    "        evidence_count = len(gap.get('evidence', []))\n",
    "        \n",
    "        # Simple heuristic: impact * evidence * 10 hours\n",
    "        estimated_hours = impact * evidence_count * 10\n",
    "        estimated_cost = estimated_hours * AVG_HOURLY_RATE\n",
    "        \n",
    "        gap_costs.append({\n",
    "            'gap_id': gap['id'],\n",
    "            'type': gap['type'],\n",
    "            'impact_score': impact,\n",
    "            'estimated_hours': estimated_hours,\n",
    "            'estimated_cost_usd': estimated_cost,\n",
    "        })\n",
    "        \n",
    "        total_estimated_hours += estimated_hours\n",
    "    \n",
    "    # Create cost DataFrame\n",
    "    cost_df = pd.DataFrame(gap_costs)\n",
    "    \n",
    "    print(\"\\nCost Estimation:\")\n",
    "    print(\"=\" * 80)\n",
    "    display(cost_df)\n",
    "    \n",
    "    # Summary\n",
    "    total_cost = cost_df['estimated_cost_usd'].sum()\n",
    "    print(f\"\\nTotal Estimated Impact:\")\n",
    "    print(f\"  - Engineering hours wasted: {total_estimated_hours:.1f} hours\")\n",
    "    print(f\"  - Estimated cost: ${total_cost:,.2f}\")\n",
    "    print(f\"  - Average cost per gap: ${total_cost/len(gaps):,.2f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cost_df.plot(x='gap_id', y='estimated_cost_usd', kind='bar', \n",
    "                 color='coral', edgecolor='black', legend=False)\n",
    "    plt.xlabel('Gap ID')\n",
    "    plt.ylabel('Estimated Cost (USD)')\n",
    "    plt.title('Estimated Organizational Cost by Gap')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No gaps available for cost estimation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Actionable Recommendations\n",
    "\n",
    "Extract and summarize recommendations for resolving detected gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps and len(gaps) > 0:\n",
    "    print(\"Actionable Recommendations:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, gap in enumerate(gaps, 1):\n",
    "        print(f\"\\n{i}. Gap: {gap['id']}\")\n",
    "        print(f\"   Type: {gap['type']}\")\n",
    "        print(f\"   Impact: {gap['impact_score']:.2f}\")\n",
    "        print(f\"   Teams: {', '.join(gap.get('teams_involved', []))}\")\n",
    "        \n",
    "        if 'recommendation' in gap:\n",
    "            print(f\"\\n   Recommendation:\")\n",
    "            print(f\"   {gap['recommendation']}\")\n",
    "        else:\n",
    "            print(f\"\\n   Recommendation: [To be generated by LLM]\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"No recommendations available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Results\n",
    "\n",
    "Export the analysis results for further processing or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gaps and len(gaps) > 0:\n",
    "    # Export to JSON\n",
    "    export_data = {\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'total_gaps': len(gaps),\n",
    "        'metadata': detection_result.get('metadata', {}),\n",
    "        'gaps': gaps,\n",
    "    }\n",
    "    \n",
    "    output_file = 'gap_analysis_results.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Results exported to: {output_file}\")\n",
    "    \n",
    "    # Export summary to CSV\n",
    "    if 'gap_summary' in dir():\n",
    "        csv_file = 'gap_summary.csv'\n",
    "        gap_summary.to_csv(csv_file, index=False)\n",
    "        print(f\"✓ Summary exported to: {csv_file}\")\n",
    "else:\n",
    "    print(\"No results to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **API Integration**: Using the Gap Detection API programmatically\n",
    "2. **Gap Analysis**: Understanding detected coordination failures\n",
    "3. **Entity Extraction**: Identifying teams and people involved\n",
    "4. **Impact Assessment**: Quantifying organizational cost\n",
    "5. **Visualization**: Exploring patterns in coordination gaps\n",
    "6. **Recommendations**: Actionable steps to resolve gaps\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Load Real Data**: Connect to actual Slack/GitHub/Google Docs sources\n",
    "2. **Tune Detection**: Adjust thresholds based on your organization\n",
    "3. **Monitor Trends**: Track gap detection over time\n",
    "4. **Act on Gaps**: Implement recommendations to improve coordination\n",
    "5. **Measure Impact**: Quantify time and cost savings\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Gap Detection Documentation](../docs/GAP_DETECTION.md)\n",
    "- [Entity Extraction Guide](../docs/ENTITY_EXTRACTION.md)\n",
    "- [API Examples](../docs/API_EXAMPLES.md)\n",
    "- [README](../README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
